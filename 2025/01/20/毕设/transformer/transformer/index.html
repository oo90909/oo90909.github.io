<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="整体计算框图 自注意力机制代码全过程在以上过程中，value从未变化，最终得到的矩阵shape分别是attn: (2,4,512)p_attn:(2,4,4) 没有掩码张量： 有掩码张量：可以看到最终的矩阵很规整 图示全过程（忽略了掩码张量）要注意，上面的式子是很多个值求和的结果q: query ,一段文本k: key,提示词v: value,根据key在脑海中形成的文章概括 多头自注意力机制多个">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="整体计算框图 自注意力机制代码全过程在以上过程中，value从未变化，最终得到的矩阵shape分别是attn: (2,4,512)p_attn:(2,4,4) 没有掩码张量： 有掩码张量：可以看到最终的矩阵很规整 图示全过程（忽略了掩码张量）要注意，上面的式子是很多个值求和的结果q: query ,一段文本k: key,提示词v: value,根据key在脑海中形成的文章概括 多头自注意力机制多个">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-9.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-12.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-10.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-11.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-13.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-14.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-1.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-2.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-3.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-4.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-5.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-6.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-7.png">
<meta property="og:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-8.png">
<meta property="article:published_time" content="2025-01-20T07:27:44.662Z">
<meta property="article:modified_time" content="2025-02-26T17:35:35.343Z">
<meta property="article:author" content="fathergun">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-9.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://oo90909.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-毕设/transformer/transformer" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/" class="article-date">
  <time class="dt-published" datetime="2025-01-20T07:27:44.662Z" itemprop="datePublished">2025-01-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>整体计算框图</p>
<h3 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h3><h4 id="代码全过程"><a href="#代码全过程" class="headerlink" title="代码全过程"></a>代码全过程</h4><p><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-9.png" alt="alt text"><br>在以上过程中，value从未变化，最终得到的矩阵shape分别是<br>attn: (2,4,512)<br>p_attn:(2,4,4)</p>
<h5 id="没有掩码张量："><a href="#没有掩码张量：" class="headerlink" title="没有掩码张量："></a>没有掩码张量：</h5><p><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-12.png" alt="alt text"><br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-10.png" alt="alt text"><br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-11.png" alt="alt text"></p>
<h5 id="有掩码张量："><a href="#有掩码张量：" class="headerlink" title="有掩码张量："></a>有掩码张量：</h5><p>可以看到最终的矩阵很规整<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-13.png" alt="alt text"><br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-14.png" alt="alt text"></p>
<h4 id="图示全过程（忽略了掩码张量）"><a href="#图示全过程（忽略了掩码张量）" class="headerlink" title="图示全过程（忽略了掩码张量）"></a>图示全过程（忽略了掩码张量）</h4><p><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image.png" alt="Alt text"><br>要注意，上面的式子是很多个值求和的结果<br>q: query ,一段文本<br>k: key,提示词<br>v: value,根据key在脑海中形成的文章概括<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-1.png" alt="Alt text"></p>
<h3 id="多头自注意力机制"><a href="#多头自注意力机制" class="headerlink" title="多头自注意力机制"></a>多头自注意力机制</h3><p>多个网络层<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-2.png" alt="Alt text"></p>
<p><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-3.png" alt="Alt text"><br>传入位置信息，这里的t是位置矩阵，用于控制x在位置上面的权重，具体如何控制？需要再看看<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-4.png" alt="Alt text"><br>Add&amp;Norm:Add是X+muti-head Attention(X),Norm是LayerNorm，用于提高模型的训练速度<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-5.png" alt="Alt text"></p>
<h3 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h3><p>将string转化为数字<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-6.png" alt="Alt text"><br>每一行对应一个单词，每一列对应一个位置信息，每一个单元格就是对应的每一个单词在某一个位置<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-7.png" alt="Alt text"></p>
<p> transformer库<br><img src="/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/image-8.png" alt="Alt text"></p>
<p>sequence2sequence:<br>输入一个句子，输出一个由机器决定长度的句子</p>
<h3 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h3><p>将文字转化为向量</p>
<h4 id="嵌入层"><a href="#嵌入层" class="headerlink" title="嵌入层"></a>嵌入层</h4><p>将输入的向量升维，升维以后的向量是为了更好体现相互之间的关系</p>
<p>d_model：词嵌入的维度<br>vocab：词汇表的映射数量</p>
<h4 id="位置编码器"><a href="#位置编码器" class="headerlink" title="位置编码器"></a>位置编码器</h4><p>将嵌入层得到的向量加入位置信息</p>
<p>d_model：词嵌入的维度<br>dropout：让百分之多少的神经元失效<br>max_len:每个句子最大长度</p>
<p>unsqueeze():为向量增加一个维度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])  <span class="comment"># shape [3]</span></span><br><span class="line">y = x.unsqueeze(<span class="number">0</span>)           <span class="comment"># shape [1, 3] → 行向量</span></span><br><span class="line">z = x.unsqueeze(<span class="number">1</span>)           <span class="comment"># shape [3, 1] → 列向量</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="comment"># tensor([[1, 2, 3]])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"><span class="comment"># tensor([[1],</span></span><br><span class="line"><span class="comment">#         [2],</span></span><br><span class="line"><span class="comment">#         [3]])</span></span><br></pre></td></tr></table></figure>

<p>掩码矩阵：防止未来才需要使用的矩阵信息提前被使用，所以用掩码矩阵来遮掩<br>掩码的使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">scores=scores.masked_fill(mask==<span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line"><span class="comment"># 这里的mask是掩码张量，形似</span></span><br><span class="line">[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line"> [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line"> [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]]</span><br><span class="line"> <span class="comment"># scores是注意力得分张量，形似</span></span><br><span class="line">[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line"> [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],</span><br><span class="line"> [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line"> <span class="comment"># masked_fill是torch的函数，作用是将mask中为0的位置在scores中用-1e9替换</span></span><br><span class="line"> <span class="comment"># 这样在softmax中，-1e9会接近0，所以这些位置在softmax中几乎不会起作用</span></span><br><span class="line"> <span class="comment">#最后得到的矩阵就是</span></span><br><span class="line"> [[-<span class="number">1e9</span>, <span class="number">2</span>  , <span class="number">3</span>],</span><br><span class="line">  [-<span class="number">1e9</span>,-<span class="number">1e9</span>, <span class="number">6</span>],</span><br><span class="line">  [-<span class="number">1e9</span>,-<span class="number">1e9</span>,-<span class="number">1e9</span>]]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h3><h4 id="softmax层"><a href="#softmax层" class="headerlink" title="softmax层"></a>softmax层</h4><h4 id="线性层"><a href="#线性层" class="headerlink" title="线性层"></a>线性层</h4><h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><p>由n个层堆叠而成</p>
<h4 id="子层1：多头自注意力机制-规范化层-残差连接"><a href="#子层1：多头自注意力机制-规范化层-残差连接" class="headerlink" title="子层1：多头自注意力机制+规范化层+残差连接"></a>子层1：多头自注意力机制+规范化层+残差连接</h4><h4 id="子层2：前馈神经网络-规范化层-残差连接"><a href="#子层2：前馈神经网络-规范化层-残差连接" class="headerlink" title="子层2：前馈神经网络+规范化层+残差连接"></a>子层2：前馈神经网络+规范化层+残差连接</h4><h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><p>由n个层堆叠而成</p>
<h4 id="子层1：多头自注意力机制-规范化层-残差连接-1"><a href="#子层1：多头自注意力机制-规范化层-残差连接-1" class="headerlink" title="子层1：多头自注意力机制+规范化层+残差连接"></a>子层1：多头自注意力机制+规范化层+残差连接</h4><h4 id="子层2：前馈神经网络-规范化层-残差连接-1"><a href="#子层2：前馈神经网络-规范化层-残差连接-1" class="headerlink" title="子层2：前馈神经网络+规范化层+残差连接"></a>子层2：前馈神经网络+规范化层+残差连接</h4><h4 id="子层3：多头自注意力机制-规范化层-残差连接"><a href="#子层3：多头自注意力机制-规范化层-残差连接" class="headerlink" title="子层3：多头自注意力机制+规范化层+残差连接"></a>子层3：多头自注意力机制+规范化层+残差连接</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://oo90909.github.io/2025/01/20/%E6%AF%95%E8%AE%BE/transformer/transformer/" data-id="cm8ofd1bz004cd0udeiun5tgv" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/02/09/%E6%AF%95%E8%AE%BE/deepseek/deepseek%E8%AE%BA%E6%96%87/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2025/01/10/%E6%AF%95%E8%AE%BE/%E7%A5%9E%E5%A5%87%E5%AE%9D%E8%B4%9D%E5%88%86%E7%B1%BB/%E5%88%86%E7%B1%BB/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/unisewap2/" rel="tag">unisewap2</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/uniswap2/" rel="tag">uniswap2</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/uniswap3/" rel="tag">uniswap3</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/unisewap2/" style="font-size: 10px;">unisewap2</a> <a href="/tags/uniswap2/" style="font-size: 10px;">uniswap2</a> <a href="/tags/uniswap3/" style="font-size: 10px;">uniswap3</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/01/">January 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/11/">November 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">September 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/03/24/%E6%AF%95%E8%AE%BE/%E8%AF%AD%E6%B3%95mapping/%E7%BF%BB%E8%AF%91%E8%A6%81%E7%82%B9/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/03/23/%E6%AF%95%E8%AE%BE/%E8%AF%AD%E6%B3%95mapping/solidity2/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/03/20/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AE%89%E5%85%A8/%E5%8D%8F%E8%AE%AE%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/ERC1155/ERC1155/">EIP712</a>
          </li>
        
          <li>
            <a href="/2025/03/19/solana/%E5%90%84%E7%A7%8D%E7%A8%8B%E5%BA%8F%E8%B4%A6%E6%88%B7%E7%B1%BB%E5%9E%8B/%E5%8E%9F%E7%94%9F%E7%A8%8B%E5%BA%8F/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/03/17/solana/%E5%90%84%E7%A7%8D%E7%A8%8B%E5%BA%8F%E8%B4%A6%E6%88%B7%E7%B1%BB%E5%9E%8B/%E7%A8%8B%E5%BA%8F%E8%B4%A6%E6%88%B7%E7%B1%BB%E5%9E%8B/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 fathergun<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>